{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Question_Answering_LSTM.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HupN7es_6HzN",
        "outputId": "b394c9f1-a8e2-40e1-cf56-614a7f961016"
      },
      "source": [
        "pip install pyvi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyvi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/e1/0e5bc6b5e3327b9385d6e0f1b0a7c0404f28b74eb6db59a778515b30fd9c/pyvi-0.1-py2.py3-none-any.whl (8.5MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5MB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.0.1)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.7 pyvi-0.1 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJQAfTRM3hWK"
      },
      "source": [
        "from pyvi import ViTokenizer\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
        "import tensorflow as tf\n",
        "from  sklearn.model_selection import train_test_split\n",
        "\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from numpy import array_equal\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import TimeDistributed"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG3IM1wx3hWS"
      },
      "source": [
        "# Tập data chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR-AtlSn3hWT"
      },
      "source": [
        "file_tranning = ['bạn bè.txt',\n",
        "'các câu hỏi phức tạp.txt',\n",
        "'đất nước.txt',\n",
        "'địa chỉ.txt',\n",
        "'du lịch.txt',\n",
        "'gia đình.txt',\n",
        "'giải trí.txt',\n",
        "'học tập.txt',\n",
        "'nghề nghiệp.txt',\n",
        "'nghỉ lễ.txt',\n",
        "'người yêu.txt',\n",
        "'robot.txt',\n",
        "'shoping.txt',\n",
        "'tán gẫu.txt',\n",
        "'tdtu.txt',\n",
        "'thông tin cá nhân.txt',\n",
        "'trò chuyện về đi ăn.txt']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVGkrGwc3hWT"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SucZtzFM3hWU"
      },
      "source": [
        "question_train = []\n",
        "answer_train = []\n",
        "\n",
        "for i in range(len(file_tranning)):\n",
        "    with open(file_tranning[i], encoding='UTF-8') as f:\n",
        "        train_lines = f.readlines()\n",
        "        for line in train_lines:\n",
        "            tmp = line.split(\"__eou__\")\n",
        "            question_train.append(tmp[0].strip()) # strip(): Loại bỏ whitespace đầu cuối string\n",
        "            answer_train.append(tmp[1].strip())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF7dXppN3hWU",
        "outputId": "b76cff3d-d7ff-4ba2-a167-ee7c3e03f552"
      },
      "source": [
        "(question_train[:20])\n",
        "# print((answer_train[0]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thích đánh lộn không?',\n",
              " 'Solo yasua không',\n",
              " 'Mai đi picnic không?',\n",
              " 'Mai học ca mấy vậy?',\n",
              " 'Còn tiền không?',\n",
              " 'Mấy giờ rồi nhỉ?',\n",
              " 'Bao lâu rồi chưa về quê',\n",
              " 'Bạn có crush chưa',\n",
              " 'Crush bao lâu rồi',\n",
              " 'Crush có Bồ chưa?',\n",
              " 'Vậy sao còn crush ?',\n",
              " 'Bạn có bạn trai chưa?',\n",
              " 'Mai rảnh không rũ bồ đi bar chơi',\n",
              " 'Bạn có thói quen làm gì khi rảnh vậy ?',\n",
              " 'Khi bạn đi chơi cùng bạn bè thì nơi \"tủ\" của bạn là ở đâu vậy ?',\n",
              " 'Bạn có thích hút thuốc lúc rảnh không ?',\n",
              " 'Bạn có thích học bài lúc rảnh không ?',\n",
              " 'Bạn có muốn đi bơi cùng bạn bè lúc rảnh không ?',\n",
              " 'Dạo này bạn với crush sao rồi, ổn không ?',\n",
              " 'Tỏ tình với crush chưa bạn, bữa tui thấy bạn đi chung với bạn nữ nào thì phải ?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I03KWHc3hWV"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcLyXw783hWW"
      },
      "source": [
        "# Xóa question và answer khi answer empty string\n",
        "list_index_empty_answer = []"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gqq0xTR3hWW"
      },
      "source": [
        "for i in range(len(answer_train)):\n",
        "    if(answer_train[i] == \"\"):\n",
        "        list_index_empty_answer.append(i)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R_X-FyP3hWW",
        "outputId": "e167ac76-b549-44a6-90c5-dbc21480bf8b"
      },
      "source": [
        "print(list_index_empty_answer)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[423, 424, 425, 426, 427, 428, 486, 487, 488, 489, 490, 632, 633, 648, 649, 650, 651, 652, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1229, 1230, 1231, 1232, 1233, 1814, 1815, 1816, 1817, 1871, 1872, 1873, 1874, 2372, 2373, 2374, 2375, 2376, 2377, 2653, 2654, 2703, 2704, 2705, 2706, 3240, 3241, 3242, 3243, 3244, 3289, 3290, 3291, 3292, 3293, 4195, 4196, 4197, 4198, 4199, 5030, 5031, 5032, 5033, 5034, 5035, 5405]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VqKO9NQ3hWX"
      },
      "source": [
        "for i in range(len(list_index_empty_answer)):\n",
        "    del answer_train[list_index_empty_answer[i]-i]\n",
        "    del question_train[list_index_empty_answer[i]-i]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "683ZYiv53hWX"
      },
      "source": [
        "import string"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImQZlaQG3hWX"
      },
      "source": [
        "def text_process(mess):\n",
        "    # chuyển về chữ thường\n",
        "    mess = mess.lower()\n",
        "    \n",
        "    # xóa dấu câu\n",
        "    mess = [char for char in mess if char not in string.punctuation]\n",
        "    mess = ''.join(mess)\n",
        "    \n",
        "    # replace whitespace\n",
        "    mess = mess.replace(\"   \", \" \")\n",
        "    mess = mess.replace(\"  \", \" \")\n",
        "    \n",
        "    # Word Segmentation\n",
        "    mess = ViTokenizer.tokenize(mess)\n",
        "    \n",
        "    return mess"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06T5inHD3hWY"
      },
      "source": [
        "for i in range(len(question_train)):\n",
        "    question_train[i] = text_process(question_train[i])\n",
        "    answer_train[i] = text_process(answer_train[i])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VYw2qeZ3hWY"
      },
      "source": [
        "#print((question_train[631]))\n",
        "#print((answer_train[631]))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WO8bUAZ3hWZ",
        "outputId": "6981cc1b-d92d-43cb-b633-1462ffe447e2"
      },
      "source": [
        "print(question_train[0])\n",
        "print(answer_train[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "thích đánh_lộn không\n",
            "ngon nhà_vô\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh2pw7Jz3hWZ"
      },
      "source": [
        "data = question_train\n",
        "data_answer = answer_train"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFK37r_V3hWa",
        "outputId": "d9979526-6ceb-4167-b05f-44b10d0484ed"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=True,filters='!\"#$%&()*+,-./:;<=>?@[\\]^`{|}~ ',split=' ')\n",
        "\n",
        "tokenizer.fit_on_texts(data)\n",
        "print(data[0])\n",
        "print(data[1])\n",
        "print(data[2])\n",
        "\n",
        "tokenizer.fit_on_texts(data_answer)\n",
        "print(data_answer[0])\n",
        "print(data_answer[1])\n",
        "print(data_answer[2])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "thích đánh_lộn không\n",
            "solo yasua không\n",
            "mai đi picnic không\n",
            "ngon nhà_vô\n",
            "chấp lun 2 mạng đầu\n",
            "mai bận học rồi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR1dxZDTbicS"
      },
      "source": [
        "word2count = {}\n",
        "\n",
        "for line in data:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "for line in data_answer:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97-AMdyQb0xs",
        "outputId": "c4d0912b-8420-4226-fbb0-a08e4366ae2e"
      },
      "source": [
        "len(word2count)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F3wJsGXcHpX"
      },
      "source": [
        "thresh = 1\n",
        "\n",
        "vocab = {}\n",
        "word_num = 0\n",
        "for word, count in word2count.items():\n",
        "    if count >= thresh:\n",
        "        vocab[word] = word_num\n",
        "        word_num += 1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj-9mk1ScJGP",
        "outputId": "c2667ca1-a3de-43f4-a5c6-eb09a6da86ab"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKYmN8_acbH_"
      },
      "source": [
        "for i in range(len(data_answer)):\n",
        "    data_answer[i] = '<SOS> ' + data_answer[i] + ' <EOS>'\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSmdwN5JcbLe",
        "outputId": "ee62bd0d-9488-4021-8dd4-b3fda7107e3d"
      },
      "source": [
        "len(data_answer)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5537"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8tzClgBcveg"
      },
      "source": [
        "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
        "x = len(vocab)\n",
        "for token in tokens:\n",
        "    vocab[token] = x\n",
        "    x += 1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awYTCPrbdJLl",
        "outputId": "c4d4d6a8-2d0d-4bef-effc-038ac5ec4c52"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibagS3W7dUg0"
      },
      "source": [
        "vocab['cameron'] = vocab['<PAD>']\n",
        "vocab['<PAD>'] = 0"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEIbmXRAdUjs",
        "outputId": "57bd768d-1afc-4b44-c33c-d015b31e849c"
      },
      "source": [
        "inv_vocab = {w:v for v, w in vocab.items()}\n",
        "len(inv_vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKUyd15wdUo0"
      },
      "source": [
        "encoder_inp = []\n",
        "for line in data:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])\n",
        "        \n",
        "    encoder_inp.append(lst)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd9fQ9HRdUr1",
        "outputId": "975b3568-15d0-4b1f-c5e9-c9509fe70242"
      },
      "source": [
        "len(encoder_inp)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5537"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpkiPCrEdUxn"
      },
      "source": [
        "decoder_inp = []\n",
        "for line in data_answer:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])        \n",
        "    decoder_inp.append(lst)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OBrzdvWeQvI",
        "outputId": "acf1ce1b-d102-42d1-d087-d7ef0574b6a3"
      },
      "source": [
        "len(decoder_inp)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5537"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JY8IagWeQyA"
      },
      "source": [
        "encoder_inp = pad_sequences(encoder_inp, 15, padding='post', truncating='post')\n",
        "decoder_inp = pad_sequences(decoder_inp, 15, padding='post', truncating='post')\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dknn-8gDeQ0v"
      },
      "source": [
        "decoder_final_output = []\n",
        "for i in decoder_inp:\n",
        "    decoder_final_output.append(i[1:]) \n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRsRTGv1ehRg",
        "outputId": "3e4c3aa3-0d24-4442-ddb7-46420577047f"
      },
      "source": [
        "decoder_final_output[:2]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 894, 2558, 4858,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0], dtype=int32),\n",
              " array([2559, 2514,  454,  492,  475, 4858,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0], dtype=int32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XHKwO90esRi",
        "outputId": "a1f463ed-bf74-472f-9600-0c415b2f2c7c"
      },
      "source": [
        "decoder_final_output = pad_sequences(decoder_final_output, 15, padding='post', truncating='post')\n",
        "decoder_final_output[:2]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 894, 2558, 4858,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0],\n",
              "       [2559, 2514,  454,  492,  475, 4858,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ARVTDyresU8"
      },
      "source": [
        "decoder_final_output = to_categorical(decoder_final_output, len(vocab))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU2efzRdfBtY",
        "outputId": "53383ca9-90ba-4139-bafd-215dc82bdc50"
      },
      "source": [
        "print(decoder_final_output.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5537, 15, 4862)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlf6W-OEfBwk"
      },
      "source": [
        "enc_inp = Input(shape=(15, ))\n",
        "dec_inp = Input(shape=(15, ))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-LhBYggfTOa"
      },
      "source": [
        "VOCAB_SIZE = len(vocab)\n",
        "embed = Embedding(VOCAB_SIZE+1, output_dim=64, \n",
        "                  input_length=15,\n",
        "                  trainable=True                  \n",
        "                  )"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRMSDJWtfTRI"
      },
      "source": [
        "enc_embed = embed(enc_inp)\n",
        "enc_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
        "enc_op, h, c = enc_lstm(enc_embed)\n",
        "enc_states = [h, c]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KwSCUo7fTWR",
        "outputId": "c5d27c96-ce7d-4dbb-bb89-b795de48859a"
      },
      "source": [
        "dec_embed = embed(dec_inp)\n",
        "dec_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
        "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
        "\n",
        "dense = Dense(VOCAB_SIZE, activation='softmax')\n",
        "\n",
        "dense_op = dense(dec_op)\n",
        "\n",
        "model = Model([enc_inp, dec_inp], dense_op)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')\n",
        "\n",
        "model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=150,batch_size=32)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "174/174 [==============================] - 20s 96ms/step - loss: 5.0420 - acc: 0.4919\n",
            "Epoch 2/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 2.8554 - acc: 0.5735\n",
            "Epoch 3/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 2.6981 - acc: 0.5828\n",
            "Epoch 4/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 2.5509 - acc: 0.5970\n",
            "Epoch 5/150\n",
            "174/174 [==============================] - 17s 101ms/step - loss: 2.4107 - acc: 0.6063\n",
            "Epoch 6/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 2.2552 - acc: 0.6223\n",
            "Epoch 7/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 2.2046 - acc: 0.6232\n",
            "Epoch 8/150\n",
            "174/174 [==============================] - 17s 96ms/step - loss: 2.1286 - acc: 0.6283\n",
            "Epoch 9/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 2.0434 - acc: 0.6366\n",
            "Epoch 10/150\n",
            "174/174 [==============================] - 17s 96ms/step - loss: 1.9141 - acc: 0.6514\n",
            "Epoch 11/150\n",
            "174/174 [==============================] - 17s 96ms/step - loss: 1.8740 - acc: 0.6553\n",
            "Epoch 12/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 1.8378 - acc: 0.6558\n",
            "Epoch 13/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 1.7598 - acc: 0.6629\n",
            "Epoch 14/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 1.6431 - acc: 0.6796\n",
            "Epoch 15/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 1.6357 - acc: 0.6766\n",
            "Epoch 16/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 1.5886 - acc: 0.6841\n",
            "Epoch 17/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 1.5027 - acc: 0.6978\n",
            "Epoch 18/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 1.4598 - acc: 0.7044\n",
            "Epoch 19/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 1.3842 - acc: 0.7175\n",
            "Epoch 20/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 1.3621 - acc: 0.7203\n",
            "Epoch 21/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 1.3171 - acc: 0.7269\n",
            "Epoch 22/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 1.2785 - acc: 0.7350\n",
            "Epoch 23/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 1.1866 - acc: 0.7523\n",
            "Epoch 24/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 1.1756 - acc: 0.7543\n",
            "Epoch 25/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 1.1433 - acc: 0.7599\n",
            "Epoch 26/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 1.1023 - acc: 0.7669\n",
            "Epoch 27/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 1.0775 - acc: 0.7741\n",
            "Epoch 28/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 1.0478 - acc: 0.7771\n",
            "Epoch 29/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 1.0379 - acc: 0.7793\n",
            "Epoch 30/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 1.0083 - acc: 0.7853\n",
            "Epoch 31/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.9558 - acc: 0.7964\n",
            "Epoch 32/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.9268 - acc: 0.8022\n",
            "Epoch 33/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 0.9332 - acc: 0.8000\n",
            "Epoch 34/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 0.8750 - acc: 0.8120\n",
            "Epoch 35/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.8587 - acc: 0.8146\n",
            "Epoch 36/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.8212 - acc: 0.8230\n",
            "Epoch 37/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.8068 - acc: 0.8255\n",
            "Epoch 38/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 0.7785 - acc: 0.8346\n",
            "Epoch 39/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 0.7831 - acc: 0.8309\n",
            "Epoch 40/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.7397 - acc: 0.8412\n",
            "Epoch 41/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 0.7252 - acc: 0.8432\n",
            "Epoch 42/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.7083 - acc: 0.8486\n",
            "Epoch 43/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 0.6901 - acc: 0.8508\n",
            "Epoch 44/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.7083 - acc: 0.8462\n",
            "Epoch 45/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.6727 - acc: 0.8542\n",
            "Epoch 46/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.6425 - acc: 0.8623\n",
            "Epoch 47/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.6142 - acc: 0.8675\n",
            "Epoch 48/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 0.6141 - acc: 0.8683\n",
            "Epoch 49/150\n",
            "174/174 [==============================] - 18s 105ms/step - loss: 0.5914 - acc: 0.8731\n",
            "Epoch 50/150\n",
            "174/174 [==============================] - 22s 124ms/step - loss: 0.5812 - acc: 0.8758\n",
            "Epoch 51/150\n",
            "174/174 [==============================] - 24s 136ms/step - loss: 0.5608 - acc: 0.8794\n",
            "Epoch 52/150\n",
            "174/174 [==============================] - 18s 104ms/step - loss: 0.5466 - acc: 0.8827\n",
            "Epoch 53/150\n",
            "174/174 [==============================] - 21s 118ms/step - loss: 0.5361 - acc: 0.8845\n",
            "Epoch 54/150\n",
            "174/174 [==============================] - 20s 113ms/step - loss: 0.5705 - acc: 0.8735\n",
            "Epoch 55/150\n",
            "174/174 [==============================] - 19s 109ms/step - loss: 0.5050 - acc: 0.8933\n",
            "Epoch 56/150\n",
            "174/174 [==============================] - 22s 126ms/step - loss: 0.4955 - acc: 0.8938\n",
            "Epoch 57/150\n",
            "174/174 [==============================] - 23s 134ms/step - loss: 0.4731 - acc: 0.9012\n",
            "Epoch 58/150\n",
            "174/174 [==============================] - 25s 141ms/step - loss: 0.4641 - acc: 0.9021\n",
            "Epoch 59/150\n",
            "174/174 [==============================] - 20s 116ms/step - loss: 0.4393 - acc: 0.9080\n",
            "Epoch 60/150\n",
            "174/174 [==============================] - 20s 114ms/step - loss: 0.4517 - acc: 0.9038\n",
            "Epoch 61/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 0.4554 - acc: 0.9001\n",
            "Epoch 62/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.4422 - acc: 0.9045\n",
            "Epoch 63/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.4105 - acc: 0.9126\n",
            "Epoch 64/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.4092 - acc: 0.9133\n",
            "Epoch 65/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.3826 - acc: 0.9198\n",
            "Epoch 66/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.3685 - acc: 0.9236\n",
            "Epoch 67/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.3567 - acc: 0.9275\n",
            "Epoch 68/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.3542 - acc: 0.9261\n",
            "Epoch 69/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.3552 - acc: 0.9247\n",
            "Epoch 70/150\n",
            "174/174 [==============================] - 17s 97ms/step - loss: 0.3550 - acc: 0.9250\n",
            "Epoch 71/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.3469 - acc: 0.9267\n",
            "Epoch 72/150\n",
            "174/174 [==============================] - 19s 108ms/step - loss: 0.3359 - acc: 0.9302\n",
            "Epoch 73/150\n",
            "174/174 [==============================] - 18s 103ms/step - loss: 0.3125 - acc: 0.9360\n",
            "Epoch 74/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.3138 - acc: 0.9369\n",
            "Epoch 75/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.3431 - acc: 0.9242\n",
            "Epoch 76/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.2951 - acc: 0.9397\n",
            "Epoch 77/150\n",
            "174/174 [==============================] - 18s 104ms/step - loss: 0.2910 - acc: 0.9399\n",
            "Epoch 78/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 0.2760 - acc: 0.9445\n",
            "Epoch 79/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.2614 - acc: 0.9488\n",
            "Epoch 80/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.2506 - acc: 0.9520\n",
            "Epoch 81/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.2581 - acc: 0.9487\n",
            "Epoch 82/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 0.2464 - acc: 0.9511\n",
            "Epoch 83/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.2654 - acc: 0.9456\n",
            "Epoch 84/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.2660 - acc: 0.9454\n",
            "Epoch 85/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.2456 - acc: 0.9496\n",
            "Epoch 86/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.2296 - acc: 0.9542\n",
            "Epoch 87/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.2253 - acc: 0.9553\n",
            "Epoch 88/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 0.2097 - acc: 0.9596\n",
            "Epoch 89/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 0.2047 - acc: 0.9627\n",
            "Epoch 90/150\n",
            "174/174 [==============================] - 19s 109ms/step - loss: 0.1893 - acc: 0.9652\n",
            "Epoch 91/150\n",
            "174/174 [==============================] - 18s 102ms/step - loss: 0.1897 - acc: 0.9654\n",
            "Epoch 92/150\n",
            "174/174 [==============================] - 18s 102ms/step - loss: 0.1881 - acc: 0.9646\n",
            "Epoch 93/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 0.1994 - acc: 0.9614\n",
            "Epoch 94/150\n",
            "174/174 [==============================] - 18s 102ms/step - loss: 0.1928 - acc: 0.9617\n",
            "Epoch 95/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.2042 - acc: 0.9577\n",
            "Epoch 96/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.1876 - acc: 0.9629\n",
            "Epoch 97/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 0.2097 - acc: 0.9558\n",
            "Epoch 98/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.1749 - acc: 0.9664\n",
            "Epoch 99/150\n",
            "174/174 [==============================] - 18s 105ms/step - loss: 0.1585 - acc: 0.9715\n",
            "Epoch 100/150\n",
            "174/174 [==============================] - 22s 128ms/step - loss: 0.1515 - acc: 0.9729\n",
            "Epoch 101/150\n",
            "174/174 [==============================] - 19s 110ms/step - loss: 0.1406 - acc: 0.9750\n",
            "Epoch 102/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.1376 - acc: 0.9756\n",
            "Epoch 103/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.1447 - acc: 0.9734\n",
            "Epoch 104/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.1466 - acc: 0.9735\n",
            "Epoch 105/150\n",
            "174/174 [==============================] - 18s 102ms/step - loss: 0.1605 - acc: 0.9673\n",
            "Epoch 106/150\n",
            "174/174 [==============================] - 19s 107ms/step - loss: 0.1672 - acc: 0.9665\n",
            "Epoch 107/150\n",
            "174/174 [==============================] - 18s 105ms/step - loss: 0.2687 - acc: 0.9358\n",
            "Epoch 108/150\n",
            "174/174 [==============================] - 18s 103ms/step - loss: 0.1666 - acc: 0.9663\n",
            "Epoch 109/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 0.1450 - acc: 0.9724\n",
            "Epoch 110/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.1248 - acc: 0.9767\n",
            "Epoch 111/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.1105 - acc: 0.9816\n",
            "Epoch 112/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.1025 - acc: 0.9827\n",
            "Epoch 113/150\n",
            "174/174 [==============================] - 18s 102ms/step - loss: 0.1021 - acc: 0.9823\n",
            "Epoch 114/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.0963 - acc: 0.9843\n",
            "Epoch 115/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.0959 - acc: 0.9838\n",
            "Epoch 116/150\n",
            "174/174 [==============================] - 18s 102ms/step - loss: 0.0926 - acc: 0.9840\n",
            "Epoch 117/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.1060 - acc: 0.9812\n",
            "Epoch 118/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.1047 - acc: 0.9812\n",
            "Epoch 119/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.1211 - acc: 0.9753\n",
            "Epoch 120/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.1344 - acc: 0.9706\n",
            "Epoch 121/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.1466 - acc: 0.9684\n",
            "Epoch 122/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.1219 - acc: 0.9764\n",
            "Epoch 123/150\n",
            "174/174 [==============================] - 18s 103ms/step - loss: 0.1198 - acc: 0.9753\n",
            "Epoch 124/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.0928 - acc: 0.9838\n",
            "Epoch 125/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.0840 - acc: 0.9854\n",
            "Epoch 126/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.0803 - acc: 0.9857\n",
            "Epoch 127/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.0704 - acc: 0.9878\n",
            "Epoch 128/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.0706 - acc: 0.9875\n",
            "Epoch 129/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.0677 - acc: 0.9881\n",
            "Epoch 130/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.0684 - acc: 0.9876\n",
            "Epoch 131/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.0680 - acc: 0.9878\n",
            "Epoch 132/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 0.0698 - acc: 0.9872\n",
            "Epoch 133/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.0681 - acc: 0.9871\n",
            "Epoch 134/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.0722 - acc: 0.9865\n",
            "Epoch 135/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.1009 - acc: 0.9790\n",
            "Epoch 136/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.1324 - acc: 0.9688\n",
            "Epoch 137/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 0.1220 - acc: 0.9723\n",
            "Epoch 138/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.1032 - acc: 0.9778\n",
            "Epoch 139/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.0768 - acc: 0.9852\n",
            "Epoch 140/150\n",
            "174/174 [==============================] - 17s 100ms/step - loss: 0.0619 - acc: 0.9885\n",
            "Epoch 141/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.0557 - acc: 0.9894\n",
            "Epoch 142/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.0564 - acc: 0.9889\n",
            "Epoch 143/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.0516 - acc: 0.9896\n",
            "Epoch 144/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.0493 - acc: 0.9898\n",
            "Epoch 145/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 0.0501 - acc: 0.9895\n",
            "Epoch 146/150\n",
            "174/174 [==============================] - 18s 101ms/step - loss: 0.0525 - acc: 0.9896\n",
            "Epoch 147/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.0547 - acc: 0.9887\n",
            "Epoch 148/150\n",
            "174/174 [==============================] - 17s 98ms/step - loss: 0.0546 - acc: 0.9887\n",
            "Epoch 149/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.0694 - acc: 0.9847\n",
            "Epoch 150/150\n",
            "174/174 [==============================] - 17s 99ms/step - loss: 0.0792 - acc: 0.9826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd2ae4a9e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzFSdGAbfTZL"
      },
      "source": [
        "enc_model = Model([enc_inp], enc_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(128,))\n",
        "decoder_state_input_c = Input(shape=(128,))\n",
        "\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = dec_lstm(dec_embed , \n",
        "                                    initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "dec_model = Model([dec_inp]+ decoder_states_inputs,\n",
        "                                      [decoder_outputs]+ decoder_states)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ji8xMv70fTbZ",
        "outputId": "132e17a9-c24d-47aa-bca0-28f278ed4a27"
      },
      "source": [
        "print(\"##########################################\")\n",
        "print(\"#       start chatting        #\")\n",
        "print(\"##########################################\")\n",
        "\n",
        "prepro1 = \"\"\n",
        "while prepro1 != 'q':\n",
        "  prepro1  = input(\"you : \")\n",
        "  prepro1 = text_process(prepro1)\n",
        "  prepro = [prepro1]\n",
        "  txt = []\n",
        "  for x in prepro:\n",
        "    lst = []\n",
        "    for y in x.split():\n",
        "      try:\n",
        "        lst.append(vocab[y])\n",
        "      except:\n",
        "        lst.append(vocab['<OUT>'])\n",
        "    txt.append(lst)\n",
        "    txt = pad_sequences(txt, 15, padding='post')\n",
        "\n",
        "    stat = enc_model.predict( txt )\n",
        "    empty_target_seq = np.zeros( ( 1 , 1) )\n",
        "    empty_target_seq[0, 0] = vocab['<SOS>']\n",
        "    stop_condition = False\n",
        "\n",
        "    decoded_translation = ''\n",
        "\n",
        "    while not stop_condition :\n",
        "      dec_outputs , h, c= dec_model.predict([empty_target_seq] + stat )\n",
        "      decoder_concat_input = dense(dec_outputs)\n",
        "      sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n",
        "      sampled_word = inv_vocab[sampled_word_index] + ' '\n",
        "\n",
        "      if sampled_word != '<EOS> ':\n",
        "        decoded_translation += sampled_word\n",
        "      if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
        "        stop_condition = True\n",
        "\n",
        "      empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "      empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "\n",
        "      stat = [h, c]\n",
        "    print(\"chatbot attention : \", decoded_translation )\n",
        "    print(\"==============================================\")  "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################\n",
            "#       start chatting        #\n",
            "##########################################\n",
            "you : xin chào\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 15) for input KerasTensor(type_spec=TensorSpec(shape=(None, 15), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "chatbot attention :  chào bạn bạn muốn tôi giúp gì \n",
            "==============================================\n",
            "you : bạn có phải robot\n",
            "chatbot attention :  bạn có 20k \n",
            "==============================================\n",
            "you : bạn cho mình hả\n",
            "chatbot attention :  bạn ấy bạn nhé \n",
            "==============================================\n",
            "you : bạn đang làm gì vậy\n",
            "chatbot attention :  có \n",
            "==============================================\n",
            "you : bạn học trường nào\n",
            "chatbot attention :  mình học trường tôn đức thắng \n",
            "==============================================\n",
            "you : bạn học khoa gì\n",
            "chatbot attention :  mình học khoa công_nghệ thông_tin \n",
            "==============================================\n",
            "you : bạn có người yêu chưa\n",
            "chatbot attention :  mình chưa có người_yêu \n",
            "==============================================\n",
            "you : giữa nam và nữ bạn chọn ai\n",
            "chatbot attention :  quá xinh_đẹp là đằng khác \n",
            "==============================================\n",
            "you : vậy bạn ăn tối hay ăn trưa\n",
            "chatbot attention :  lát mình ăn lẩu mẹ nấu \n",
            "==============================================\n",
            "you : oh. thế bạn có cho mình ăn cùng không\n",
            "chatbot attention :  đương_nhiên rồi mình cũng <PAD> nấu_ăn bạn lắm \n",
            "==============================================\n",
            "you : bạn đi đâu đấy\n",
            "chatbot attention :  đi về nhà \n",
            "==============================================\n",
            "you : nhà bạn ở đâu\n",
            "chatbot attention :  nhà mình ở quận 11 \n",
            "==============================================\n",
            "you : ở quận 11  có gì hay không\n",
            "chatbot attention :  đi du_lịch với gia_đình nên ở trong 2 lần bạn \n",
            "==============================================\n",
            "you : đi du lịch ở đâu\n",
            "chatbot attention :  đà_lạt \n",
            "==============================================\n",
            "you : ngoài đà lạt bạn có muốn đi đâu không\n",
            "chatbot attention :  có 2 lần bạn cho bạn cho lắm \n",
            "==============================================\n",
            "you : bạn có bao nhiêu người bạn\n",
            "chatbot attention :  nhiều \n",
            "==============================================\n",
            "you : bạn là ai\n",
            "chatbot attention :  xin chào mình là robot tiếp_tân tại trường đh tôn đức thắng \n",
            "==============================================\n",
            "you : gia đình bạn có bao nhiêu người\n",
            "chatbot attention :  gia_đình mình có 5 người \n",
            "==============================================\n",
            "you : trường học có thân thiện không\n",
            "chatbot attention :  chị bao lắm \n",
            "==============================================\n",
            "you : chị bạn đẹp lắm hả\n",
            "chatbot attention :  rất tốt \n",
            "==============================================\n",
            "you : đẹp và tốt bạn phân biệt được chứ\n",
            "chatbot attention :  trời quang năm khi vào tuần \n",
            "==============================================\n",
            "you : bạn đang nói gì vậy\n",
            "chatbot attention :  mình đang qua những người có_thể thông_minh \n",
            "==============================================\n",
            "you : bạn đang chọc mình à\n",
            "chatbot attention :  đúng rồi bạn \n",
            "==============================================\n",
            "you : muốn đánh lộn không\n",
            "chatbot attention :  vũng_tàu \n",
            "==============================================\n",
            "you : muốn đánh nhau không\n",
            "chatbot attention :  cũng thường_xuyên có buồn lắm \n",
            "==============================================\n",
            "you : so lo không\n",
            "chatbot attention :  đi đâu cũng được \n",
            "==============================================\n",
            "you : solo không thằng nhóc\n",
            "chatbot attention :  1m8 \n",
            "==============================================\n",
            "you : đánh nhau không\n",
            "chatbot attention :  mình có xài cái đây rồi \n",
            "==============================================\n",
            "you : mày nói gì đấy \n",
            "chatbot attention :  mày đang rảnh \n",
            "==============================================\n",
            "you : nói rỏ ra cho tao xem \n",
            "chatbot attention :  mai tao với mày nên tạo ra \n",
            "==============================================\n",
            "you : thằng chó này tao fix sml giờ mày ngu hơn cả tao à\n",
            "chatbot attention :  chắc là iphone tui được 2 nha \n",
            "==============================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-4154283e3693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprepro1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mprepro1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mprepro1\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mprepro1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepro1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mprepro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprepro1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OauGpLfUqgZW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPciLSGxp0ut"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}