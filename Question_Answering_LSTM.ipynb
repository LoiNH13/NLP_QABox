{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Question_Answering_LSTM.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HupN7es_6HzN",
        "outputId": "b394c9f1-a8e2-40e1-cf56-614a7f961016"
      },
      "source": [
        "pip install pyvi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJQAfTRM3hWK"
      },
      "source": [
        "from pyvi import ViTokenizer\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
        "import tensorflow as tf\n",
        "from  sklearn.model_selection import train_test_split\n",
        "\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from numpy import array_equal\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import TimeDistributed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG3IM1wx3hWS"
      },
      "source": [
        "# Tập data chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR-AtlSn3hWT"
      },
      "source": [
        "file_tranning = ['bạn bè.txt',\n",
        "'các câu hỏi phức tạp.txt',\n",
        "'đất nước.txt',\n",
        "'địa chỉ.txt',\n",
        "'du lịch.txt',\n",
        "'gia đình.txt',\n",
        "'giải trí.txt',\n",
        "'học tập.txt',\n",
        "'nghề nghiệp.txt',\n",
        "'nghỉ lễ.txt',\n",
        "'người yêu.txt',\n",
        "'robot.txt',\n",
        "'shoping.txt',\n",
        "'tán gẫu.txt',\n",
        "'tdtu.txt',\n",
        "'thông tin cá nhân.txt',\n",
        "'trò chuyện về đi ăn.txt']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVGkrGwc3hWT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SucZtzFM3hWU"
      },
      "source": [
        "question_train = []\n",
        "answer_train = []\n",
        "\n",
        "for i in range(len(file_tranning)):\n",
        "    with open(file_tranning[i], encoding='UTF-8') as f:\n",
        "        train_lines = f.readlines()\n",
        "        for line in train_lines:\n",
        "            tmp = line.split(\"__eou__\")\n",
        "            question_train.append(tmp[0].strip()) # strip(): Loại bỏ whitespace đầu cuối string\n",
        "            answer_train.append(tmp[1].strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF7dXppN3hWU",
        "outputId": "b76cff3d-d7ff-4ba2-a167-ee7c3e03f552"
      },
      "source": [
        "(question_train[:20])\n",
        "# print((answer_train[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I03KWHc3hWV"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcLyXw783hWW"
      },
      "source": [
        "# Xóa question và answer khi answer empty string\n",
        "list_index_empty_answer = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gqq0xTR3hWW"
      },
      "source": [
        "for i in range(len(answer_train)):\n",
        "    if(answer_train[i] == \"\"):\n",
        "        list_index_empty_answer.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R_X-FyP3hWW",
        "outputId": "e167ac76-b549-44a6-90c5-dbc21480bf8b"
      },
      "source": [
        "print(list_index_empty_answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VqKO9NQ3hWX"
      },
      "source": [
        "for i in range(len(list_index_empty_answer)):\n",
        "    del answer_train[list_index_empty_answer[i]-i]\n",
        "    del question_train[list_index_empty_answer[i]-i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "683ZYiv53hWX"
      },
      "source": [
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImQZlaQG3hWX"
      },
      "source": [
        "def text_process(mess):\n",
        "    # chuyển về chữ thường\n",
        "    mess = mess.lower()\n",
        "    \n",
        "    # xóa dấu câu\n",
        "    mess = [char for char in mess if char not in string.punctuation]\n",
        "    mess = ''.join(mess)\n",
        "    \n",
        "    # replace whitespace\n",
        "    mess = mess.replace(\"   \", \" \")\n",
        "    mess = mess.replace(\"  \", \" \")\n",
        "    \n",
        "    # Word Segmentation\n",
        "    mess = ViTokenizer.tokenize(mess)\n",
        "    \n",
        "    return mess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06T5inHD3hWY"
      },
      "source": [
        "for i in range(len(question_train)):\n",
        "    question_train[i] = text_process(question_train[i])\n",
        "    answer_train[i] = text_process(answer_train[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VYw2qeZ3hWY"
      },
      "source": [
        "#print((question_train[631]))\n",
        "#print((answer_train[631]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WO8bUAZ3hWZ",
        "outputId": "6981cc1b-d92d-43cb-b633-1462ffe447e2"
      },
      "source": [
        "print(question_train[0])\n",
        "print(answer_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh2pw7Jz3hWZ"
      },
      "source": [
        "data = question_train\n",
        "data_answer = answer_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFK37r_V3hWa",
        "outputId": "d9979526-6ceb-4167-b05f-44b10d0484ed"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=True,filters='!\"#$%&()*+,-./:;<=>?@[\\]^`{|}~ ',split=' ')\n",
        "\n",
        "tokenizer.fit_on_texts(data)\n",
        "print(data[0])\n",
        "print(data[1])\n",
        "print(data[2])\n",
        "\n",
        "tokenizer.fit_on_texts(data_answer)\n",
        "print(data_answer[0])\n",
        "print(data_answer[1])\n",
        "print(data_answer[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR1dxZDTbicS"
      },
      "source": [
        "word2count = {}\n",
        "\n",
        "for line in data:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "for line in data_answer:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97-AMdyQb0xs",
        "outputId": "c4d0912b-8420-4226-fbb0-a08e4366ae2e"
      },
      "source": [
        "len(word2count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F3wJsGXcHpX"
      },
      "source": [
        "thresh = 1\n",
        "\n",
        "vocab = {}\n",
        "word_num = 0\n",
        "for word, count in word2count.items():\n",
        "    if count >= thresh:\n",
        "        vocab[word] = word_num\n",
        "        word_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj-9mk1ScJGP",
        "outputId": "c2667ca1-a3de-43f4-a5c6-eb09a6da86ab"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKYmN8_acbH_"
      },
      "source": [
        "for i in range(len(data_answer)):\n",
        "    data_answer[i] = '<SOS> ' + data_answer[i] + ' <EOS>'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSmdwN5JcbLe",
        "outputId": "ee62bd0d-9488-4021-8dd4-b3fda7107e3d"
      },
      "source": [
        "len(data_answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8tzClgBcveg"
      },
      "source": [
        "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
        "x = len(vocab)\n",
        "for token in tokens:\n",
        "    vocab[token] = x\n",
        "    x += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awYTCPrbdJLl",
        "outputId": "c4d4d6a8-2d0d-4bef-effc-038ac5ec4c52"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibagS3W7dUg0"
      },
      "source": [
        "vocab['cameron'] = vocab['<PAD>']\n",
        "vocab['<PAD>'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEIbmXRAdUjs",
        "outputId": "57bd768d-1afc-4b44-c33c-d015b31e849c"
      },
      "source": [
        "inv_vocab = {w:v for v, w in vocab.items()}\n",
        "len(inv_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKUyd15wdUo0"
      },
      "source": [
        "encoder_inp = []\n",
        "for line in data:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])\n",
        "        \n",
        "    encoder_inp.append(lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd9fQ9HRdUr1",
        "outputId": "975b3568-15d0-4b1f-c5e9-c9509fe70242"
      },
      "source": [
        "len(encoder_inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpkiPCrEdUxn"
      },
      "source": [
        "decoder_inp = []\n",
        "for line in data_answer:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])        \n",
        "    decoder_inp.append(lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OBrzdvWeQvI",
        "outputId": "acf1ce1b-d102-42d1-d087-d7ef0574b6a3"
      },
      "source": [
        "len(decoder_inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JY8IagWeQyA"
      },
      "source": [
        "encoder_inp = pad_sequences(encoder_inp, 15, padding='post', truncating='post')\n",
        "decoder_inp = pad_sequences(decoder_inp, 15, padding='post', truncating='post')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dknn-8gDeQ0v"
      },
      "source": [
        "decoder_final_output = []\n",
        "for i in decoder_inp:\n",
        "    decoder_final_output.append(i[1:]) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRsRTGv1ehRg",
        "outputId": "3e4c3aa3-0d24-4442-ddb7-46420577047f"
      },
      "source": [
        "decoder_final_output[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XHKwO90esRi",
        "outputId": "a1f463ed-bf74-472f-9600-0c415b2f2c7c"
      },
      "source": [
        "decoder_final_output = pad_sequences(decoder_final_output, 15, padding='post', truncating='post')\n",
        "decoder_final_output[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ARVTDyresU8"
      },
      "source": [
        "decoder_final_output = to_categorical(decoder_final_output, len(vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU2efzRdfBtY",
        "outputId": "53383ca9-90ba-4139-bafd-215dc82bdc50"
      },
      "source": [
        "print(decoder_final_output.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlf6W-OEfBwk"
      },
      "source": [
        "enc_inp = Input(shape=(15, ))\n",
        "dec_inp = Input(shape=(15, ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-LhBYggfTOa"
      },
      "source": [
        "VOCAB_SIZE = len(vocab)\n",
        "embed = Embedding(VOCAB_SIZE+1, output_dim=64, \n",
        "                  input_length=15,\n",
        "                  trainable=True                  \n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRMSDJWtfTRI"
      },
      "source": [
        "enc_embed = embed(enc_inp)\n",
        "enc_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
        "enc_op, h, c = enc_lstm(enc_embed)\n",
        "enc_states = [h, c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KwSCUo7fTWR",
        "outputId": "c5d27c96-ce7d-4dbb-bb89-b795de48859a"
      },
      "source": [
        "dec_embed = embed(dec_inp)\n",
        "dec_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
        "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
        "\n",
        "dense = Dense(VOCAB_SIZE, activation='softmax')\n",
        "\n",
        "dense_op = dense(dec_op)\n",
        "\n",
        "model = Model([enc_inp, dec_inp], dense_op)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')\n",
        "\n",
        "model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=150,batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzFSdGAbfTZL"
      },
      "source": [
        "enc_model = Model([enc_inp], enc_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(128,))\n",
        "decoder_state_input_c = Input(shape=(128,))\n",
        "\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = dec_lstm(dec_embed , \n",
        "                                    initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "dec_model = Model([dec_inp]+ decoder_states_inputs,\n",
        "                                      [decoder_outputs]+ decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ji8xMv70fTbZ",
        "outputId": "132e17a9-c24d-47aa-bca0-28f278ed4a27"
      },
      "source": [
        "print(\"##########################################\")\n",
        "print(\"#       start chatting        #\")\n",
        "print(\"##########################################\")\n",
        "\n",
        "prepro1 = \"\"\n",
        "while prepro1 != 'q':\n",
        "  prepro1  = input(\"you : \")\n",
        "  prepro1 = text_process(prepro1)\n",
        "  prepro = [prepro1]\n",
        "  txt = []\n",
        "  for x in prepro:\n",
        "    lst = []\n",
        "    for y in x.split():\n",
        "      try:\n",
        "        lst.append(vocab[y])\n",
        "      except:\n",
        "        lst.append(vocab['<OUT>'])\n",
        "    txt.append(lst)\n",
        "    txt = pad_sequences(txt, 15, padding='post')\n",
        "\n",
        "    stat = enc_model.predict( txt )\n",
        "    empty_target_seq = np.zeros( ( 1 , 1) )\n",
        "    empty_target_seq[0, 0] = vocab['<SOS>']\n",
        "    stop_condition = False\n",
        "\n",
        "    decoded_translation = ''\n",
        "\n",
        "    while not stop_condition :\n",
        "      dec_outputs , h, c= dec_model.predict([empty_target_seq] + stat )\n",
        "      decoder_concat_input = dense(dec_outputs)\n",
        "      sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n",
        "      sampled_word = inv_vocab[sampled_word_index] + ' '\n",
        "\n",
        "      if sampled_word != '<EOS> ':\n",
        "        decoded_translation += sampled_word\n",
        "      if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
        "        stop_condition = True\n",
        "\n",
        "      empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "      empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "\n",
        "      stat = [h, c]\n",
        "    print(\"chatbot attention : \", decoded_translation )\n",
        "    print(\"==============================================\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OauGpLfUqgZW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPciLSGxp0ut"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}